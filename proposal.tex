\documentclass[a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{xcolor}
    \newcommand{\todo}[1]{\textcolor{red}{[ #1 ]}}
    \newcommand{\instruction}[1]{\textcolor{orange}{#1}}
    % \renewcommand{\instruction}[1]{} % Uncomment to hide instructions.

\newcommand{\hidden}[1]{}

\usepackage{biblatex}
    \addbibresource{references.bib}

\usepackage[colorlinks=false]{hyperref}

\title{STATS 402 - Interdisciplinary Data Analysis\\
    Resource-Constrained Deep Reinforcement Learning for Battlesnake\\
    Milestone Report: Stage 1
}
\author{Sichang He\\
    sichang.he@dukekunshan.edu.cn
}

\begin{document}
\maketitle

\subparagraph{Abstract}

\todo{Insert a very brief paragraph describing your project (200 words)}

\section{Project Rationale}

\todo{explain the motivation of the project
    selection by analyzing the characteristics of the selected data set,
    as well as the development trend of related fields, application prospects,
    and commonly used methods}

Battlesnake~\cite{battlesnake}
is a popular online programming competition in the form of a simultaneous
multiplayer board game. Similar to the arcade snake game,
each player controls a snake in real time on a finite grid board to be the last
one alive; the snake can change directions within each turn,
grow in length by eating randomly spawned food,
die from colliding with walls or snake bodies,
or starve to death after not eating for a long time (100 turns).
Instead of having human players control the snakes, in Battlesnake,
players develop a computer program to control their snakes' directions in each
turn, by implementing a web server that answers the game server's request.
This means players can implement their algorithms freely,
as long as they can finish answering the request within the time limitation
(500ms).

\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{snake_game_screenshot.png}
    \caption{A Standard Battlesnake Game with 4 Snakes on A 11x11 Board.
        The transparent snake is already dead.
    }
    \label{fig:game}
\end{figure}

Battlesnake is an ideal target for implementing deep reinforcement learning.
Traditionally,
the leader board is occupied by players employing various heuristics and Monte
Carlo tree search algorithms,
most notably minimax~\cite{hill2018building,binnersley2020battlesnake}. However,
more recently,
even well-defined heuristics and tree search algorithms are only adequate for
intermediate-level gameplay~\cite{schier2019adversarial}. Additionally,
given the large search space (over $(3^n)^t$ raw possibilities for $t$ turns in
a game with $n$ snakes),
tree search algorithms are computationally demanding even when techniques like
alpha-beta pruning are employed. This cost problem is magnified,
especially considering the game sets a 500ms action time limit.
To address these problems, we compare Battlesnake to the game of Go,
which also has a large possibility space and potentially long time horizon,
and AlphaGo has demonstrated that deep reinforcement learning can excel in such
situations and achieve superhuman-level performance~\cite{silver2016mastering}.
More recent examples of deep reinforcement learning systems acing video games
include OpenAI Five defeating human world champions in Dota 2,
a much more complicated online multiplayer battle game~\cite{berner2019dota}.
Therefore,
it is sensible that deep reinforcement learning can possibly be employed to
build state-of-the-art Battlesnake agents.

A deeper aspect to explore is developing deep reinforcement learning agents to
operate in resource-constrained environments.
Most Battlesnake players are amateurs hosting their web servers on cheap VMs on
cloud platforms or Raspberry Pi
computers\footnote{\url{https://play.battlesnake.com/leaderboard/standard}.}.
Similar to these resource-constrained environments, use cases,
such as autonomous spacecraft control,
have seen deep reinforcement learning applied in
them~\cite{harris2022generation}. More closely related,
proximal policy optimization (PPO)~\cite{schulman2017proximal},
the same deep reinforcement learning technique employed by OpenAI Five,
has been successfully deployed in compute and memory-limited robotic control,
specifically quadrotor navigation~\cite{huang2023collision,hegde2023hyperppo}.
Thus,
developing a deep reinforcement learning Battlesnake agent capable of operating
on low-capability devices,
like low-tier cloud VMs and Raspberry Pis, should be feasible;
such solutions would also demonstrate more fairness and practical contributions
among the competition.

\section{Research Content and Objectives}

\todo{and critical scientific problems to be solved}

\section{Research Plan and Feasibility Analysis}

\todo{including research methods, technical routes, experimental methods,
    key technologies, etc.}

\section{Features, Innovations and the Expected Results}

\instruction{
    PENALTY FOR PLAGIARISM:\\
    \(\geq 30\%\): ZERO SCORE for the report.\\
    \((25\%,30\%\): -1.5 points\\
    \((20\%,\ 25\%\): -1.0 points\\
    (15\%, 20\%]: -0.5 points\\
    \(\leq 15\%\): no penalty, you will get 2 points
}

\printbibliography

\end{document}
